"use strict";(self.webpackChunk_0_yukali_0_github_io=self.webpackChunk_0_yukali_0_github_io||[]).push([[2504],{7256:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>u,frontMatter:()=>i,metadata:()=>s,toc:()=>l});var t=a(4848),r=a(8453);const i={id:"cancerwithray",title:"Ray\u5206\u6563\u5f0f\u8a13\u7df4-\u764c\u75c7\u7d30\u80de\u8a3a\u65b7"},o="Cancer",s={id:"kubernetes-native/mlops/ray/train/kaggle/cancerwithray",title:"Ray\u5206\u6563\u5f0f\u8a13\u7df4-\u764c\u75c7\u7d30\u80de\u8a3a\u65b7",description:"\u8cc7\u6599\u4f86\u6e90",source:"@site/docs/kubernetes-native/mlops/ray/train/kaggle/cancerwithray.md",sourceDirName:"kubernetes-native/mlops/ray/train/kaggle",slug:"/kubernetes-native/mlops/ray/train/kaggle/cancerwithray",permalink:"/docs/kubernetes-native/mlops/ray/train/kaggle/cancerwithray",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/kubernetes-native/mlops/ray/train/kaggle/cancerwithray.md",tags:[],version:"current",frontMatter:{id:"cancerwithray",title:"Ray\u5206\u6563\u5f0f\u8a13\u7df4-\u764c\u75c7\u7d30\u80de\u8a3a\u65b7"}},c={},l=[{value:"\u8cc7\u6599\u4f86\u6e90",id:"\u8cc7\u6599\u4f86\u6e90",level:2},{value:"Ray\u7a0b\u5f0f\u78bc",id:"ray\u7a0b\u5f0f\u78bc",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",p:"p",pre:"pre",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"cancer",children:"Cancer"})}),"\n",(0,t.jsx)(n.h2,{id:"\u8cc7\u6599\u4f86\u6e90",children:"\u8cc7\u6599\u4f86\u6e90"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://www.kaggle.com/datasets/erdemtaha/cancer-data/data",children:"kaggle\u984c\u76ee\u7db2\u5740"})}),"\n",(0,t.jsx)(n.h2,{id:"ray\u7a0b\u5f0f\u78bc",children:"Ray\u7a0b\u5f0f\u78bc"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import torch\nfrom torch import nn\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\n\nimport pandas as pd\n\nclass CustomDataset(Dataset):\n    def __init__(self, x, y):\n        self.dataset = x\n        self.labels = y\n    def __len__(self):\n        return len(self.labels)\n    def __getitem__(self, idx):\n        x = self.dataset.iloc[idx]\n        y = self.labels.iloc[idx]\n        return torch.tensor(x.values).float(), torch.tensor([y]).float()\n\ndef CreateDataset(path="/home/user/camcer/Cancer_Data.csv"):\n    df = pd.read_csv(path)\n    df = df.loc[:, ~df.columns.str.contains(\'^Unnamed\')]\n    x = df.iloc[: ,2:].astype("float")\n    df["diagnosis"] = df["diagnosis"].apply(lambda x: 1 if x == \'M\' else 0)\n    y = df["diagnosis"].astype("int")\n    dataset = CustomDataset(x=x, y=y)\n    return dataset\n\nclass NeuralNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(30, 40),\n            nn.ReLU(),\n            nn.Linear(40, 40),\n            nn.ReLU(),\n            nn.Linear(40, 40),\n            nn.ReLU(),\n            nn.Linear(40, 1),\n            nn.Sigmoid(),\n        )\n    def forward(self, x):\n        return self.linear_relu_stack(x)\n\ndef train(epoch, device, dataloader, model, criterion, optimizer):\n    for epoch in range(epoch):\n        for X, y in dataloader:\n            model.train()\n            optimizer.zero_grad()\n            X, y = X.to(device), y.to(device)\n            pred = model(X)\n            loss = criterion(pred, y)\n            loss.backward()\n            optimizer.step()\n        metrics = {"loss": loss.item(), "epoch": epoch}\n        if ray.train.get_context().get_world_rank() == 0:\n            print(metrics)\n\nimport ray.train.torch\ndef train_func(config):\n    batch_size = 64\n    device = (\n        "cuda"\n        if torch.cuda.is_available()\n        else "cpu"\n    )\n    model = NeuralNetwork().to(device)\n    criterion = nn.BCELoss()\n    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n\n    dataset = CreateDataset()\n    dataloader = DataLoader(dataset, batch_size)\n\n    model = ray.train.torch.prepare_model(model)\n    dataloader = ray.train.torch.prepare_data_loader(dataloader)\n\n    train(10, device, dataloader, model, criterion, optimizer)\n\nscaling_config = ray.train.ScalingConfig(num_workers=4, use_gpu=False)\ntrainer = ray.train.torch.TorchTrainer(\n    train_func,\n    scaling_config=scaling_config,\n)\nresult = trainer.fit()\n'})})]})}function u(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,a)=>{a.d(n,{R:()=>o,x:()=>s});var t=a(6540);const r={},i=t.createContext(r);function o(e){const n=t.useContext(i);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),t.createElement(i.Provider,{value:n},e.children)}}}]);