"use strict";(self.webpackChunk_0yukali0=self.webpackChunk_0yukali0||[]).push([[188],{3905:(e,n,r)=>{r.d(n,{Zo:()=>p,kt:()=>f});var t=r(7294);function a(e,n,r){return n in e?Object.defineProperty(e,n,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[n]=r,e}function o(e,n){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),r.push.apply(r,t)}return r}function i(e){for(var n=1;n<arguments.length;n++){var r=null!=arguments[n]?arguments[n]:{};n%2?o(Object(r),!0).forEach((function(n){a(e,n,r[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):o(Object(r)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(r,n))}))}return e}function l(e,n){if(null==e)return{};var r,t,a=function(e,n){if(null==e)return{};var r,t,a={},o=Object.keys(e);for(t=0;t<o.length;t++)r=o[t],n.indexOf(r)>=0||(a[r]=e[r]);return a}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(t=0;t<o.length;t++)r=o[t],n.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(a[r]=e[r])}return a}var s=t.createContext({}),c=function(e){var n=t.useContext(s),r=n;return e&&(r="function"==typeof e?e(n):i(i({},n),e)),r},p=function(e){var n=c(e.components);return t.createElement(s.Provider,{value:n},e.children)},d="mdxType",m={inlineCode:"code",wrapper:function(e){var n=e.children;return t.createElement(t.Fragment,{},n)}},u=t.forwardRef((function(e,n){var r=e.components,a=e.mdxType,o=e.originalType,s=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),d=c(r),u=a,f=d["".concat(s,".").concat(u)]||d[u]||m[u]||o;return r?t.createElement(f,i(i({ref:n},p),{},{components:r})):t.createElement(f,i({ref:n},p))}));function f(e,n){var r=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var o=r.length,i=new Array(o);i[0]=u;var l={};for(var s in n)hasOwnProperty.call(n,s)&&(l[s]=n[s]);l.originalType=e,l[d]="string"==typeof e?e:a,i[1]=l;for(var c=2;c<o;c++)i[c]=r[c];return t.createElement.apply(null,i)}return t.createElement.apply(null,r)}u.displayName="MDXCreateElement"},4794:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>s,contentTitle:()=>i,default:()=>m,frontMatter:()=>o,metadata:()=>l,toc:()=>c});var t=r(7462),a=(r(7294),r(3905));const o={id:"example",title:"\u7bc4\u4f8b"},i="\u4f7f\u7528 ray train\u7684\u61c9\u7528\u6848\u4f8b",l={unversionedId:"ray/train/example",id:"ray/train/example",title:"\u7bc4\u4f8b",description:"\u521d\u968e",source:"@site/docs/ray/train/example.md",sourceDirName:"ray/train",slug:"/ray/train/example",permalink:"/docs/ray/train/example",draft:!1,editUrl:"https://github.com/0yukali0/0yukali0.github.io/docs/ray/train/example.md",tags:[],version:"current",frontMatter:{id:"example",title:"\u7bc4\u4f8b"},sidebar:"tutorialSidebar",previous:{title:"\u4ecb\u7d39",permalink:"/docs/ray/train/"},next:{title:"Ray Train\u652f\u63f4\u4e4bframework",permalink:"/docs/ray/train/supported_framwork"}},s={},c=[{value:"\u521d\u968e",id:"\u521d\u968e",level:2},{value:"Pytorch",id:"pytorch",level:3},{value:"\u4e2d\u968e",id:"\u4e2d\u968e",level:2},{value:"\u9032\u968e",id:"\u9032\u968e",level:2}],p={toc:c},d="wrapper";function m(e){let{components:n,...r}=e;return(0,a.kt)(d,(0,t.Z)({},p,r,{components:n,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"\u4f7f\u7528-ray-train\u7684\u61c9\u7528\u6848\u4f8b"},"\u4f7f\u7528 ray train\u7684\u61c9\u7528\u6848\u4f8b"),(0,a.kt)("h2",{id:"\u521d\u968e"},"\u521d\u968e"),(0,a.kt)("h3",{id:"pytorch"},"Pytorch"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},'import os\nfrom filelock import fileLock\nfrom typing import Dict\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nfrom torchvision.transforms import ToTensor, Normalize\nfrom tqdm import tqdm\n\nimport ray.train\nfrom ray.train import ScalingConfig\nfrom ray.train.torch import TorchTrainer\n\ndef get_dataloaders(batch_size):\n    transform = transforms.Compose([ToTensor(), Normalize((0.5),(0.5),)])\n    with FileLock(os.path.expanduser("~/data.lock"))\n        training_data = datasets.FashionMNIST(\n            root="~/data",\n            train=True,\n            download=True,\n            transform=transform\n        )\n        test_data = datasets.FashionMNIST(\n            root="~/data",\n            train=False,\n            download=True,\n            transform=transform\n        )\n        train_dataloader = DataLoader(training_data, batch_size=batch_size)\n        test_dataloader = DataLoader(test)\n    return train_dataloader, test_dataloader\n\nclass NeuralNetwork(nn.Module):\n    def __init__(self):\n        super(NeuralNetwork, self).__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(28 * 28, 512),\n            nn.ReLU(),\n            nn.Dropout(0.25),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Dropout(0.25),\n            nn.Linear(512, 10),\n            nn.ReLU(),\n        )\n    def foward(self, x):\n        logits = self.linear_relu_stack(self.flatten(x))\n        return logits\n\ndef train_func(config):\n    ir = config["lr"]\n    epochs = config["epochs"]\n    batch_size = config["batch_size_per_worker"]\n\n    train_dataloader, test_dataloader = get_dataloaders(\n        batch_size=batch_size,\n    )\n\n    model = NeuralNetwork()\n    train_dataloader = ray.train.prepare_data_loader(train_dataloader)\n    test_dataloader = ray.train.prepare_data_loeader(teste_dataloader)\n    model = ray.train.torch.prepare_model(model)\n    loss_fn = nn.CrossEntropyLiss()\n    optimizer = torch.optim.SGD(\n        model.parameters(),\n        lr=lr,\n        momentum=0.9,\n    )\n\n    for epoch in range(epochs):\n        model.train()\n        for X, y in tqdm(train_dataloader, desc=f"Train Epoch .{epoch}"):\n            pred = model(X)\n            loss = loss_fn(pred, y)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n        model.eval()\n        test_loss, num_correct, num_total = 0, 0, 0\n        with torch.no_grad():\n            for X, y in tqdm(test_dataloader, desc=f"Test Epoch.{epoch}."):\n                pred = model(X)\n                loss = loss_fn(pred, y)\n                test_loss += loss.item()\n                num_total += y.shape[0]\n                num_correct += (pred.argmax(1) == y).sum().item()\n\n           test_loss /= len(test_dataloader)\n           accuracy = num_correct / num_total\n           ray.train.report(metrics={"loss": test_loss, "accuracy": accuracy})\n\ndef train_fashion_MNIST(num_worker=2, use_gpu=False):\n    global_batch_size = 32\n    train_config = {\n        "lr": 1e-3,\n        "epochs": 10,\n        "batch_size_per_worker": global_batch_size,\n    }\n\n    scaling_config = ScalingConfig(number_workers=num_workers, use_gpu=use_gpu)\n\n    trainer = TorchTrainer(\n        train_loop_per_worker=train_func,\n        train_loop_config=train_config,\n        scaling_config=scaling_config,\n    )\n\n    result = trainer.fit()\n    print(f"Training result:{result}")\n\nif __name__ == "__main__":\n    train_fashion_mnist(num_workers=4, use_gpu=True)\n')),(0,a.kt)("h2",{id:"\u4e2d\u968e"},"\u4e2d\u968e"),(0,a.kt)("h2",{id:"\u9032\u968e"},"\u9032\u968e"))}m.isMDXComponent=!0}}]);