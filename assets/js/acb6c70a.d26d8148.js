"use strict";(self.webpackChunk_0yukali0=self.webpackChunk_0yukali0||[]).push([[751],{3905:(e,r,t)=>{t.d(r,{Zo:()=>d,kt:()=>b});var n=t(7294);function a(e,r,t){return r in e?Object.defineProperty(e,r,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[r]=t,e}function l(e,r){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);r&&(n=n.filter((function(r){return Object.getOwnPropertyDescriptor(e,r).enumerable}))),t.push.apply(t,n)}return t}function i(e){for(var r=1;r<arguments.length;r++){var t=null!=arguments[r]?arguments[r]:{};r%2?l(Object(t),!0).forEach((function(r){a(e,r,t[r])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):l(Object(t)).forEach((function(r){Object.defineProperty(e,r,Object.getOwnPropertyDescriptor(t,r))}))}return e}function o(e,r){if(null==e)return{};var t,n,a=function(e,r){if(null==e)return{};var t,n,a={},l=Object.keys(e);for(n=0;n<l.length;n++)t=l[n],r.indexOf(t)>=0||(a[t]=e[t]);return a}(e,r);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(n=0;n<l.length;n++)t=l[n],r.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var s=n.createContext({}),p=function(e){var r=n.useContext(s),t=r;return e&&(t="function"==typeof e?e(r):i(i({},r),e)),t},d=function(e){var r=p(e.components);return n.createElement(s.Provider,{value:r},e.children)},c="mdxType",m={inlineCode:"code",wrapper:function(e){var r=e.children;return n.createElement(n.Fragment,{},r)}},u=n.forwardRef((function(e,r){var t=e.components,a=e.mdxType,l=e.originalType,s=e.parentName,d=o(e,["components","mdxType","originalType","parentName"]),c=p(t),u=a,b=c["".concat(s,".").concat(u)]||c[u]||m[u]||l;return t?n.createElement(b,i(i({ref:r},d),{},{components:t})):n.createElement(b,i({ref:r},d))}));function b(e,r){var t=arguments,a=r&&r.mdxType;if("string"==typeof e||a){var l=t.length,i=new Array(l);i[0]=u;var o={};for(var s in r)hasOwnProperty.call(r,s)&&(o[s]=r[s]);o.originalType=e,o[c]="string"==typeof e?e:a,i[1]=o;for(var p=2;p<l;p++)i[p]=t[p];return n.createElement.apply(null,i)}return n.createElement.apply(null,t)}u.displayName="MDXCreateElement"},109:(e,r,t)=>{t.r(r),t.d(r,{assets:()=>s,contentTitle:()=>i,default:()=>m,frontMatter:()=>l,metadata:()=>o,toc:()=>p});var n=t(7462),a=(t(7294),t(3905));const l={id:"mllib-linear",title:"linear"},i=void 0,o={unversionedId:"spark/spark_mllib/mllib-linear",id:"spark/spark_mllib/mllib-linear",title:"linear",description:"SVM",source:"@site/docs/spark/spark_mllib/mllib-linear.md",sourceDirName:"spark/spark_mllib",slug:"/spark/spark_mllib/mllib-linear",permalink:"/docs/spark/spark_mllib/mllib-linear",draft:!1,editUrl:"https://github.com/0yukali0/0yukali0.github.io/docs/spark/spark_mllib/mllib-linear.md",tags:[],version:"current",frontMatter:{id:"mllib-linear",title:"linear"},sidebar:"tutorialSidebar",previous:{title:"pyspark",permalink:"/docs/spark/pyspark"},next:{title:"zookeeper\u53e2\u96c6\u5efa\u7acb",permalink:"/docs/zookeeper/buildzookeeper"}},s={},p=[{value:"SVM",id:"svm",level:2},{value:"LogisticRegression",id:"logisticregression",level:2}],d={toc:p},c="wrapper";function m(e){let{components:r,...t}=e;return(0,a.kt)(c,(0,n.Z)({},d,t,{components:r,mdxType:"MDXLayout"}),(0,a.kt)("h2",{id:"svm"},"SVM"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'from pyspark.mllib.classification import SVMWithSGD, SVMModel\nfrom pyspark.mllib.regression import LabeledPoint\n\n# Load and parse the data\ndef parsePoint(line):\n    values = [float(x) for x in line.split(\' \')]\n    return LabeledPoint(values[0], values[1:])\n\ndata = sc.textFile("data/mllib/sample_svm_data.txt")\nparsedData = data.map(parsePoint)\n\n# Build the model\nmodel = SVMWithSGD.train(parsedData, iterations=100)\n\n# Evaluating the model on training data\nlabelsAndPreds = parsedData.map(lambda p: (p.label, model.predict(p.features)))\ntrainErr = labelsAndPreds.filter(lambda lp: lp[0] != lp[1]).count() / float(parsedData.count())\nprint("Training Error = " + str(trainErr))\n\n# Save and load model\nmodel.save(sc, "target/tmp/pythonSVMWithSGDModel")\nsameModel = SVMModel.load(sc, "target/tmp/pythonSVMWithSGDModel")\n')),(0,a.kt)("h2",{id:"logisticregression"},"LogisticRegression"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel\nfrom pyspark.mllib.regression import LabeledPoint\n\n\n# Build the model\nmodel = LogisticRegressionWithLBFGS.train(parsedData)\n\n# Evaluating the model on training data\nlabelsAndPreds = parsedData.map(lambda p: (p.label, model.predict(p.features)))\ntrainErr = labelsAndPreds.filter(lambda lp: lp[0] != lp[1]).count() / float(parsedData.count())\nprint("Training Error = " + str(trainErr))\n\n# Save and load model\nmodel.save(sc, "target/tmp/pythonLogisticRegressionWithLBFGSModel")\nsameModel = LogisticRegressionModel.load(sc, "target/tmp/pythonLogisticRegressionWithLBFGSModel")\n')))}m.isMDXComponent=!0}}]);