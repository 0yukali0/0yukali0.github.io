"use strict";(self.webpackChunk_0yukali0=self.webpackChunk_0yukali0||[]).push([[6496],{3905:(e,t,a)=>{a.d(t,{Zo:()=>c,kt:()=>m});var r=a(7294);function n(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,r)}return a}function s(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){n(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,r,n=function(e,t){if(null==e)return{};var a,r,n={},o=Object.keys(e);for(r=0;r<o.length;r++)a=o[r],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)a=o[r],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}var p=r.createContext({}),i=function(e){var t=r.useContext(p),a=t;return e&&(a="function"==typeof e?e(t):s(s({},t),e)),a},c=function(e){var t=i(e.components);return r.createElement(p.Provider,{value:t},e.children)},d="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},k=r.forwardRef((function(e,t){var a=e.components,n=e.mdxType,o=e.originalType,p=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),d=i(a),k=n,m=d["".concat(p,".").concat(k)]||d[k]||u[k]||o;return a?r.createElement(m,s(s({ref:t},c),{},{components:a})):r.createElement(m,s({ref:t},c))}));function m(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var o=a.length,s=new Array(o);s[0]=k;var l={};for(var p in t)hasOwnProperty.call(t,p)&&(l[p]=t[p]);l.originalType=e,l[d]="string"==typeof e?e:n,s[1]=l;for(var i=2;i<o;i++)s[i]=a[i];return r.createElement.apply(null,s)}return r.createElement.apply(null,a)}k.displayName="MDXCreateElement"},462:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>p,contentTitle:()=>s,default:()=>u,frontMatter:()=>o,metadata:()=>l,toc:()=>i});var r=a(7462),n=(a(7294),a(3905));const o={id:"rrd",title:"spark-RRD"},s=void 0,l={unversionedId:"hadoop-native/spark/base/rrd",id:"hadoop-native/spark/base/rrd",title:"spark-RRD",description:"\x3c!--",source:"@site/docs/hadoop-native/spark/base/rrd.md",sourceDirName:"hadoop-native/spark/base",slug:"/hadoop-native/spark/base/rrd",permalink:"/docs/hadoop-native/spark/base/rrd",draft:!1,editUrl:"https://github.com/0yukali0/0yukali0.github.io/docs/hadoop-native/spark/base/rrd.md",tags:[],version:"current",frontMatter:{id:"rrd",title:"spark-RRD"},sidebar:"tutorialSidebar",previous:{title:"ozone\u53e2\u96c6\u5efa\u7acb",permalink:"/docs/hadoop-native/ozone/buildozone"},next:{title:"pyspark",permalink:"/docs/hadoop-native/spark/pyspark"}},p={},i=[{value:"\u5982\u4f55\u5f15\u7528",id:"\u5982\u4f55\u5f15\u7528",level:2},{value:"Parallelized Collections",id:"parallelized-collections",level:3},{value:"External Datasets",id:"external-datasets",level:3},{value:"RDD \u64cd\u4f5c",id:"rdd-\u64cd\u4f5c",level:2},{value:"\u81ea\u8a02\u8cc7\u6599\u8655\u7406\u51fd\u6578\u65bcspark",id:"\u81ea\u8a02\u8cc7\u6599\u8655\u7406\u51fd\u6578\u65bcspark",level:3}],c={toc:i},d="wrapper";function u(e){let{components:t,...a}=e;return(0,n.kt)(d,(0,r.Z)({},c,a,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"resilient-distributed-datasets-rrds"},"Resilient Distributed Datasets (RRDs)"),(0,n.kt)("h2",{id:"\u5982\u4f55\u5f15\u7528"},"\u5982\u4f55\u5f15\u7528"),(0,n.kt)("p",null,(0,n.kt)("strong",{parentName:"p"},(0,n.kt)("em",{parentName:"strong"},"SparkConf")),"\u70ba\u914d\u7f6e\u6a94\uff0c\u900f\u904esetAppName\u8207setMaster\u4f86\u8a2d\u5b9a\u61c9\u7528\u540d\u7a31\u8207\u90e8\u5c6c\u6a21\u5f0f\u3002\n\u96a8\u5f8c\u5c07SparkConf\u4e1f\u5165",(0,n.kt)("strong",{parentName:"p"},(0,n.kt)("em",{parentName:"strong"},"JavaSparkContext")),"\u4e2d\uff0c\u5efa\u7acbspark session\u3002"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},'import org.apache.spark.SparkConf; \nimport org.apache.spark.api.java.JavaSparkContext;\nimport org.apache.spark.api.java.JavaRDD;\n\nSparkConf conf = new SparkConf().setAppName("My first spark app").setMaster("local");\nJavaSparkContext sc = new JavaSparkContext(conf);\n')),(0,n.kt)("p",null,"\u5c07\u8cc7\u6599\u5f15\u5165\u5f8c\u8f49\u5316\u70ba",(0,n.kt)("strong",{parentName:"p"},(0,n.kt)("em",{parentName:"strong"},"JavaRDD")),"\uff0c\u60c5\u6cc1\u5206\u5225\u70baParallelized Collections\u8207External Datasets\u3002"),(0,n.kt)("h3",{id:"parallelized-collections"},"Parallelized Collections"),(0,n.kt)("p",null,"Parallelized Collections:\u900f\u904espark\u7684JavaSparkContext(\u4e5f\u5c31\u662fspark session)\uff0c\u5c07Java\u539f\u751f\u8cc7\u6599\u8f49\u5316\u70baJavaRDD\u3002"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"List<Integer> data = Array.asList(1, 2, 3, 4, 5);\nJavaRDD<Integer> distData = sc.paralleize(data);\n")),(0,n.kt)("h3",{id:"external-datasets"},"External Datasets"),(0,n.kt)("p",null,"External Datasets:\u900f\u904espark\u7684JavaSparkContext(\u4e5f\u5c31\u662fspark session)\u4e4btextFile\u65b9\u6cd5\u8b80\u53d6\u3002\n\u8a72\u65b9\u6cd5\u652f\u63f4\u8207Hadoop\u76f8\u540c\uff0c\u5982local, HDFS(hdfs://your/file/path), HBase, Amazon S3(s3a://your/s3/file/path)\u3002"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},'JavaRDD<String> distFile = sc.textFile("data.txt");\n')),(0,n.kt)("h2",{id:"rdd-\u64cd\u4f5c"},"RDD \u64cd\u4f5c"),(0,n.kt)("p",null,"RRD\u64cd\u4f5c\u5206\u5169\u7a2e\uff0ctransformation\u7522\u751f\u65b0\u7684Dataset\uff0cactions\u5247\u8fd4\u56de\u503c\u3002\ntransformation\u70balazy\uff0c\u4e0d\u6703\u7acb\u5373\u8a08\u7b97\uff0c\u76f4\u5230\u8981\u6c42\u7d50\u679c\u7684\u7576\u4e0b\u3002"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},'// 1.Create data myself\nList<Integer> data = Arrays.asList(1, 2, 3, 4, 5);\nJavaRDD<Integer> distData = sc.parallelize(data);\n\n// 2.Read data from file in spark exmaples\nJavaRDD<String> lines = sc.textFile("/opt/spark/examples/src/main/resources/employees.json");\nJavaRDD<Integer> distData = lines.map(s -> s.length());\n\nint total = distData.reduce((a,b) -> a + b);\nSystem.out.println("Sum:" + total);\n')),(0,n.kt)("h3",{id:"\u81ea\u8a02\u8cc7\u6599\u8655\u7406\u51fd\u6578\u65bcspark"},"\u81ea\u8a02\u8cc7\u6599\u8655\u7406\u51fd\u6578\u65bcspark"),(0,n.kt)("p",null," Spark\u7684map\u3001reduce\u7b49\u8655\u88e1\u8cc7\u6599\u7684\u6d41\u7a0b\uff0c\u9700\u8981\u4f7f\u7528\u8005\u5b9a\u7fa9\u51fd\u6578\u4ee5\u8655\u88e1\u8cc7\u6599\u3002\n\u4e00\u7a2e\u662f\u5c07\u5b9a\u7fa9\u597d\u7684\u5be6\u4f5corg.apache.spark.api.java.function\u7684class\u50b3\u905e\u7d66spark\u3002"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"class GetLength implements Function<String, Integer> {\n   public Integer call(String s) {return s.length();}\n}\nJavaRDD<Integer> distData = lines.map(new GetLength());\n")),(0,n.kt)("p",null," \u4e00\u7a2e\u5247\u7528lambda\u3002"),(0,n.kt)("pre",null,(0,n.kt)("code",{parentName:"pre"},"JavaRDD<Integer> distData = lines.map(new Function<String, Integer>() {\n    public Integer call(String s) {return s.length();}\n});\n")))}u.isMDXComponent=!0}}]);