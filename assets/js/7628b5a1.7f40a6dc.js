"use strict";(self.webpackChunk_0yukali0=self.webpackChunk_0yukali0||[]).push([[759],{3905:(t,e,n)=>{n.d(e,{Zo:()=>p,kt:()=>g});var r=n(7294);function o(t,e,n){return e in t?Object.defineProperty(t,e,{value:n,enumerable:!0,configurable:!0,writable:!0}):t[e]=n,t}function a(t,e){var n=Object.keys(t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(t);e&&(r=r.filter((function(e){return Object.getOwnPropertyDescriptor(t,e).enumerable}))),n.push.apply(n,r)}return n}function i(t){for(var e=1;e<arguments.length;e++){var n=null!=arguments[e]?arguments[e]:{};e%2?a(Object(n),!0).forEach((function(e){o(t,e,n[e])})):Object.getOwnPropertyDescriptors?Object.defineProperties(t,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(e){Object.defineProperty(t,e,Object.getOwnPropertyDescriptor(n,e))}))}return t}function l(t,e){if(null==t)return{};var n,r,o=function(t,e){if(null==t)return{};var n,r,o={},a=Object.keys(t);for(r=0;r<a.length;r++)n=a[r],e.indexOf(n)>=0||(o[n]=t[n]);return o}(t,e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(t);for(r=0;r<a.length;r++)n=a[r],e.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(t,n)&&(o[n]=t[n])}return o}var s=r.createContext({}),c=function(t){var e=r.useContext(s),n=e;return t&&(n="function"==typeof t?t(e):i(i({},e),t)),n},p=function(t){var e=c(t.components);return r.createElement(s.Provider,{value:e},t.children)},u="mdxType",f={inlineCode:"code",wrapper:function(t){var e=t.children;return r.createElement(r.Fragment,{},e)}},d=r.forwardRef((function(t,e){var n=t.components,o=t.mdxType,a=t.originalType,s=t.parentName,p=l(t,["components","mdxType","originalType","parentName"]),u=c(n),d=o,g=u["".concat(s,".").concat(d)]||u[d]||f[d]||a;return n?r.createElement(g,i(i({ref:e},p),{},{components:n})):r.createElement(g,i({ref:e},p))}));function g(t,e){var n=arguments,o=e&&e.mdxType;if("string"==typeof t||o){var a=n.length,i=new Array(a);i[0]=d;var l={};for(var s in e)hasOwnProperty.call(e,s)&&(l[s]=e[s]);l.originalType=t,l[u]="string"==typeof t?t:o,i[1]=l;for(var c=2;c<a;c++)i[c]=n[c];return r.createElement.apply(null,i)}return r.createElement.apply(null,n)}d.displayName="MDXCreateElement"},5669:(t,e,n)=>{n.r(e),n.d(e,{assets:()=>s,contentTitle:()=>i,default:()=>f,frontMatter:()=>a,metadata:()=>l,toc:()=>c});var r=n(7462),o=(n(7294),n(3905));const a={},i=void 0,l={unversionedId:"pytorch/lightning/mnist",id:"pytorch/lightning/mnist",title:"mnist",description:"---",source:"@site/docs/pytorch/lightning/mnist.md",sourceDirName:"pytorch/lightning",slug:"/pytorch/lightning/mnist",permalink:"/blog/2024-02-13-info-blog-post/docs/pytorch/lightning/mnist",draft:!1,editUrl:"https://github.com/0yukali0/0yukali0.github.io/docs/pytorch/lightning/mnist.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"mnist",permalink:"/blog/2024-02-13-info-blog-post/docs/pytorch/kaggle/mnist"},next:{title:"Ray\u5206\u6563\u5f0f\u8a13\u7df4-\u764c\u75c7\u7d30\u80de\u8a3a\u65b7",permalink:"/blog/2024-02-13-info-blog-post/docs/ray/train/kaggle/cancerwithray"}},s={},c=[{value:"title: MNIST\u8863\u7269\u8cc7\u6599\u96c6\u5224\u65b7",id:"title-mnist\u8863\u7269\u8cc7\u6599\u96c6\u5224\u65b7",level:2},{value:"Pytorch\u7a0b\u5f0f",id:"pytorch\u7a0b\u5f0f",level:2}],p={toc:c},u="wrapper";function f(t){let{components:e,...n}=t;return(0,o.kt)(u,(0,r.Z)({},p,n,{components:e,mdxType:"MDXLayout"}),(0,o.kt)("hr",null),(0,o.kt)("p",null,"id: mnist_lightning"),(0,o.kt)("h2",{id:"title-mnist\u8863\u7269\u8cc7\u6599\u96c6\u5224\u65b7"},"title: MNIST\u8863\u7269\u8cc7\u6599\u96c6\u5224\u65b7"),(0,o.kt)("h1",{id:"mnist"},"MNIST"),(0,o.kt)("h2",{id:"pytorch\u7a0b\u5f0f"},"Pytorch\u7a0b\u5f0f"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"import torch\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor\nfrom sklearn.metrics import accuracy_score\n\nimport lightning as pl\n\nclass PytorchLightningModel(pl.LightningModule):\n    def __init__(self):\n        super().__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(28*28, 512),\n            nn.ReLU(),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Linear(512, 10)\n        )\n        self.batch_size = 64\n    def prepare_data(self):\n        self.train_set = datasets.FashionMNIST(\n            root=\"data\",\n            train=True,\n            download=True,\n            transform=ToTensor(),\n        )\n        self.val_set = datasets.FashionMNIST(\n            root=\"data\",\n            train=False,\n            download=True,\n            transform=ToTensor(),\n        )\n    def configure_optimizer(self):\n        return torch.optim.SGD(self.parameters(), lr=1e-3)\n    def train_dataloader(self):\n        return DataLoader(self.train_set, batch_size=self.batch_size, shuffle=True)\n    def val_dataloader(self):\n        return DataLoader(self.val_set, batch_size=self.batch_size, shuffle=True)\n    def forward(self, x):\n        x = self.flatten(x)\n        logits = self.linear_relu_stack(x)\n        return logits\n    def traning_step(self, batch, batch_idx):\n        x, y = batch\n        output = self.forward(x)\n        criterion = nn.CrossEntropyLoss()\n        loss = criterion(output, y)\n        logs = {'loss': loss}\n        return {'loss':loss, 'log':logs}\n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self.forward(x)\n        criterion = nn.CrossEntropyLoss()\n        loss = criterion(logits, y)\n        a, y_hat = torch.max(logits, dim=1)\n        val_acc = accuracy_score(y_hat.cpu(), y.cpu())\n        val_acc = torch.tensor(val_acc)\n        return {'val_loss': loss, 'val_acc': val_acc}\n    \n    def validation_epoch_end(self, outputs):\n        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n        avg_val_acc = torch.stack([x['val_acc'] for x in outputs]).mean()\n        tensorboard_logs = {'val_loss': avg_loss, 'avg_val_acc': avg_val_acc}\n        return {'avg_val_loss': avg_loss, 'progress_bar': tensorboard_logs}\n\nmodel = PytorchLightningModel(param1=768, param2=5)\ntrainer = pl.Trainer()\ntrainer.fit(model)\n")))}f.isMDXComponent=!0}}]);