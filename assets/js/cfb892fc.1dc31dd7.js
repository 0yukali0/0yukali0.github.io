"use strict";(self.webpackChunk_0yukali0=self.webpackChunk_0yukali0||[]).push([[59],{3905:(t,n,e)=>{e.d(n,{Zo:()=>p,kt:()=>h});var r=e(7294);function o(t,n,e){return n in t?Object.defineProperty(t,n,{value:e,enumerable:!0,configurable:!0,writable:!0}):t[n]=e,t}function a(t,n){var e=Object.keys(t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(t);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(t,n).enumerable}))),e.push.apply(e,r)}return e}function i(t){for(var n=1;n<arguments.length;n++){var e=null!=arguments[n]?arguments[n]:{};n%2?a(Object(e),!0).forEach((function(n){o(t,n,e[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(t,Object.getOwnPropertyDescriptors(e)):a(Object(e)).forEach((function(n){Object.defineProperty(t,n,Object.getOwnPropertyDescriptor(e,n))}))}return t}function s(t,n){if(null==t)return{};var e,r,o=function(t,n){if(null==t)return{};var e,r,o={},a=Object.keys(t);for(r=0;r<a.length;r++)e=a[r],n.indexOf(e)>=0||(o[e]=t[e]);return o}(t,n);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(t);for(r=0;r<a.length;r++)e=a[r],n.indexOf(e)>=0||Object.prototype.propertyIsEnumerable.call(t,e)&&(o[e]=t[e])}return o}var l=r.createContext({}),c=function(t){var n=r.useContext(l),e=n;return t&&(e="function"==typeof t?t(n):i(i({},n),t)),e},p=function(t){var n=c(t.components);return r.createElement(l.Provider,{value:n},t.children)},u="mdxType",f={inlineCode:"code",wrapper:function(t){var n=t.children;return r.createElement(r.Fragment,{},n)}},d=r.forwardRef((function(t,n){var e=t.components,o=t.mdxType,a=t.originalType,l=t.parentName,p=s(t,["components","mdxType","originalType","parentName"]),u=c(e),d=o,h=u["".concat(l,".").concat(d)]||u[d]||f[d]||a;return e?r.createElement(h,i(i({ref:n},p),{},{components:e})):r.createElement(h,i({ref:n},p))}));function h(t,n){var e=arguments,o=n&&n.mdxType;if("string"==typeof t||o){var a=e.length,i=new Array(a);i[0]=d;var s={};for(var l in n)hasOwnProperty.call(n,l)&&(s[l]=n[l]);s.originalType=t,s[u]="string"==typeof t?t:o,i[1]=s;for(var c=2;c<a;c++)i[c]=e[c];return r.createElement.apply(null,i)}return r.createElement.apply(null,e)}d.displayName="MDXCreateElement"},3336:(t,n,e)=>{e.r(n),e.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>f,frontMatter:()=>a,metadata:()=>s,toc:()=>c});var r=e(7462),o=(e(7294),e(3905));const a={},i=void 0,s={unversionedId:"python/pytorch/lightning/mnist",id:"python/pytorch/lightning/mnist",title:"mnist",description:"---",source:"@site/docs/python/pytorch/lightning/mnist.md",sourceDirName:"python/pytorch/lightning",slug:"/python/pytorch/lightning/mnist",permalink:"/docs/python/pytorch/lightning/mnist",draft:!1,editUrl:"https://github.com/0yukali0/0yukali0.github.io/docs/python/pytorch/lightning/mnist.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"mnist",permalink:"/docs/python/pytorch/kaggle/mnist"},next:{title:"Ray\u5206\u6563\u5f0f\u8a13\u7df4-\u764c\u75c7\u7d30\u80de\u8a3a\u65b7",permalink:"/docs/ray/train/kaggle/cancerwithray"}},l={},c=[{value:"title: MNIST\u8863\u7269\u8cc7\u6599\u96c6\u5224\u65b7",id:"title-mnist\u8863\u7269\u8cc7\u6599\u96c6\u5224\u65b7",level:2},{value:"Pytorch\u7a0b\u5f0f",id:"pytorch\u7a0b\u5f0f",level:2}],p={toc:c},u="wrapper";function f(t){let{components:n,...e}=t;return(0,o.kt)(u,(0,r.Z)({},p,e,{components:n,mdxType:"MDXLayout"}),(0,o.kt)("hr",null),(0,o.kt)("p",null,"id: mnist_lightning"),(0,o.kt)("h2",{id:"title-mnist\u8863\u7269\u8cc7\u6599\u96c6\u5224\u65b7"},"title: MNIST\u8863\u7269\u8cc7\u6599\u96c6\u5224\u65b7"),(0,o.kt)("h1",{id:"mnist"},"MNIST"),(0,o.kt)("h2",{id:"pytorch\u7a0b\u5f0f"},"Pytorch\u7a0b\u5f0f"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-python"},"import torch\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nfrom torchvision.transforms import ToTensor\nfrom sklearn.metrics import accuracy_score\n\nimport lightning as pl\n\nclass PytorchLightningModel(pl.LightningModule):\n    def __init__(self):\n        super().__init__()\n        self.flatten = nn.Flatten()\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(28*28, 512),\n            nn.ReLU(),\n            nn.Linear(512, 512),\n            nn.ReLU(),\n            nn.Linear(512, 10)\n        )\n        self.batch_size = 64\n    def prepare_data(self):\n        self.train_set = datasets.FashionMNIST(\n            root=\"data\",\n            train=True,\n            download=True,\n            transform=ToTensor(),\n        )\n        self.val_set = datasets.FashionMNIST(\n            root=\"data\",\n            train=False,\n            download=True,\n            transform=ToTensor(),\n        )\n    def configure_optimizer(self):\n        return torch.optim.SGD(self.parameters(), lr=1e-3)\n    def train_dataloader(self):\n        return DataLoader(self.train_set, batch_size=self.batch_size, shuffle=True)\n    def val_dataloader(self):\n        return DataLoader(self.val_set, batch_size=self.batch_size, shuffle=True)\n    def forward(self, x):\n        x = self.flatten(x)\n        logits = self.linear_relu_stack(x)\n        return logits\n    def traning_step(self, batch, batch_idx):\n        x, y = batch\n        output = self.forward(x)\n        criterion = nn.CrossEntropyLoss()\n        loss = criterion(output, y)\n        logs = {'loss': loss}\n        return {'loss':loss, 'log':logs}\n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self.forward(x)\n        criterion = nn.CrossEntropyLoss()\n        loss = criterion(logits, y)\n        a, y_hat = torch.max(logits, dim=1)\n        val_acc = accuracy_score(y_hat.cpu(), y.cpu())\n        val_acc = torch.tensor(val_acc)\n        return {'val_loss': loss, 'val_acc': val_acc}\n    \n    def validation_epoch_end(self, outputs):\n        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n        avg_val_acc = torch.stack([x['val_acc'] for x in outputs]).mean()\n        tensorboard_logs = {'val_loss': avg_loss, 'avg_val_acc': avg_val_acc}\n        return {'avg_val_loss': avg_loss, 'progress_bar': tensorboard_logs}\n\nmodel = PytorchLightningModel(param1=768, param2=5)\ntrainer = pl.Trainer()\ntrainer.fit(model)\n")))}f.isMDXComponent=!0}}]);